{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logging import getLogger\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "from recbole.model.sequential_recommender import GRU4Rec, FPMC, GRU4RecF, BERT4Rec, FOSSIL\n",
    "from recbole.model.general_recommender import BPR, FISM, DMF, FISM, ItemKNN, MultiVAE, NeuMF, SpectralCF\n",
    "from recbole.model.context_aware_recommender import DSSM\n",
    "from recbole.trainer import Trainer\n",
    "from recbole.utils import init_seed, init_logger\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/mind/preprocessed/'\n",
    "\n",
    "INTER_DATA_PATH = os.path.join(DATA_PATH, \"mind_large_train.inter\")\n",
    "ITEM_DATA_PATH = os.path.join(DATA_PATH, \"mind_large_train.item\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df = pd.read_csv(INTER_DATA_PATH, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df = pd.read_csv(ITEM_DATA_PATH, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole.quick_start import run_recbole\n",
    "from utils.utils import load_config\n",
    "cfg_path = \"./configs/general/bpr.yaml\"\n",
    "\n",
    "config_dict = load_config(cfg_path)\n",
    "run_recbole(\n",
    "    model='BPR',\n",
    "    dataset='mind_small',\n",
    "    config_dict=config_dict\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Aleksey Ryabykin\\\\Documents\\\\GitHub\\\\feed-ranking'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import load_config, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dir data\n",
      "Loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1M-48Y8oTk0p77jJ6Q_JjbteqBwo6d249 mind_small.dev.inter\n",
      "Processing file 1Ti49GHmiJJmON_VjxZgSf5zsjNMwMR5S mind_small.dev.item\n",
      "Processing file 1k-2vSdwjPvwINsOW8tHS3xAVzJ_Fewwo mind_small.train.inter\n",
      "Processing file 1z_MPGmg65M6fTcNcq1UI34cBTW6XTLFz mind_small.train.item\n",
      "Building directory structure completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder list completed\n",
      "Building directory structure\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1M-48Y8oTk0p77jJ6Q_JjbteqBwo6d249\n",
      "To: c:\\Users\\Aleksey Ryabykin\\Documents\\GitHub\\feed-ranking\\data\\preprocessed\\mind_small\\mind_small.dev.inter\n",
      "100%|██████████| 70.4M/70.4M [00:06<00:00, 11.4MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1Ti49GHmiJJmON_VjxZgSf5zsjNMwMR5S\n",
      "To: c:\\Users\\Aleksey Ryabykin\\Documents\\GitHub\\feed-ranking\\data\\preprocessed\\mind_small\\mind_small.dev.item\n",
      "100%|██████████| 33.5M/33.5M [00:02<00:00, 11.3MB/s]\n",
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1k-2vSdwjPvwINsOW8tHS3xAVzJ_Fewwo\n",
      "From (redirected): https://drive.google.com/uc?id=1k-2vSdwjPvwINsOW8tHS3xAVzJ_Fewwo&confirm=t&uuid=c16eb59d-7e3c-46b9-912f-de5cee8e34a3\n",
      "To: c:\\Users\\Aleksey Ryabykin\\Documents\\GitHub\\feed-ranking\\data\\preprocessed\\mind_small\\mind_small.train.inter\n",
      "100%|██████████| 150M/150M [00:13<00:00, 11.2MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1z_MPGmg65M6fTcNcq1UI34cBTW6XTLFz\n",
      "To: c:\\Users\\Aleksey Ryabykin\\Documents\\GitHub\\feed-ranking\\data\\preprocessed\\mind_small\\mind_small.train.item\n",
      "100%|██████████| 41.2M/41.2M [00:03<00:00, 11.3MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check c:\\Users\\Aleksey Ryabykin\\Documents\\GitHub\\feed-ranking\\data/preprocessed/mind_small\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Download completed\n"
     ]
    }
   ],
   "source": [
    "load_data(\"mind_small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def extract_metrics_from_log(log_file):\n",
    "    with open(log_file, 'r') as file:\n",
    "        log_content = file.read()\n",
    "    metrics = re.findall(r\"metrics = \\[([^]]+)\\]\", log_content)[0].split(', ')\n",
    "    metrics = [str(metric.lower())[1:-1] for metric in metrics]\n",
    "    results_dict = {}\n",
    "    for metric in metrics:\n",
    "        metric_dict = {}\n",
    "        pattern = r'{}@(\\d+) : ([\\d.]+)'.format(metric)\n",
    "        metric_matches = re.findall(pattern, log_content)\n",
    "        for key, value in metric_matches:\n",
    "            if key in metric_dict:\n",
    "                metric_dict[key].append(float(value))\n",
    "            else:\n",
    "                metric_dict[key] = [float(value)]\n",
    "        results_dict[metric] = metric_dict\n",
    "    return results_dict\n",
    "\n",
    "\n",
    "def get_best_metrics(log_file):\n",
    "    metrics = extract_metrics_from_log(log_file)\n",
    "    results = {}\n",
    "    for metric, ks in metrics.items():\n",
    "        for k, values in ks.items():\n",
    "            results[metric + \"@\" + k] = max(values)\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_last_log(model_type, dataset):\n",
    "    list_of_files = glob.glob(f'log/{model_type}/{model_type}-{dataset}-*')\n",
    "    latest_file = max(list_of_files, key=os.path.getctime)\n",
    "    return latest_file\n",
    "\n",
    "\n",
    "def update_markdown(model_type, dataset, name, log_file: str=None):\n",
    "    if log_file:\n",
    "        data = {name: get_best_metrics(log_file)}\n",
    "    else:\n",
    "        data = {name: get_best_metrics(get_last_log(model_type, dataset))}\n",
    "    metrics = [\"precision@1\", \"precision@5\", \"precision@10\",\n",
    "           \"recall@1\", \"recall@5\", \"recall@10\",\n",
    "           \"map@1\", \"map@5\", \"map@10\",\n",
    "           \"ndcg@1\", \"ndcg@5\", \"ndcg@10\"]\n",
    "\n",
    "    with open(\"README.md\", \"r\") as file:\n",
    "        markdown_content = file.read()\n",
    "\n",
    "    table_regex = r\"\\| Model .*? \\|.*?\\|\\s*\\n([\\s\\S]*?)\\n\\n\"\n",
    "    table_match = re.search(table_regex, markdown_content, re.MULTILINE)\n",
    "\n",
    "    if table_match:\n",
    "        existing_table = table_match.group(1)\n",
    "\n",
    "        table_data = [line.split(\"|\")[1:-1] for line in existing_table.split(\"\\n\") if line.strip()]\n",
    "        new_row = [name]\n",
    "        new_row.extend([str(data[name][metric]) for metric in metrics])\n",
    "        table_data.append(new_row)\n",
    "        updated_table_content = \"\\n\".join(\"| \" + \" | \".join(row) + \" |\" for row in table_data)\n",
    "\n",
    "        header = \"| Model | \" + \" | \".join(metrics) + \" |\\n\"\n",
    "        updated_markdown_content = re.sub(table_regex, f\"{header}{updated_table_content}\\n\\n\", markdown_content, flags=re.MULTILINE)\n",
    "\n",
    "        with open(\"README.md\", \"w\") as file:\n",
    "            file.write(updated_markdown_content)\n",
    "    else:\n",
    "        print(\"No table found in the Markdown file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_markdown('GRU4Rec', 'mind_small', \"GRU baseline\", 'log/GRU4Rec/GRU4Rec-mind_small-Jun-05-2023_20-30-17-03ad2b.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {: get_best_metrics(get_last_log(model_type, dataset))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = extract_metrics_from_log('log_example.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "table = \"| Model | \" + \" | \".join(metrics) + \" |\\n\"\n",
    "table += \"| --- | \" + \" | \".join([\"---\"] * len(metrics)) + \" |\\n\"\n",
    "\n",
    "table += f\"| {name}\"\n",
    "for metric in metrics:\n",
    "    table += f\" | {data[name][metric]}\"\n",
    "\n",
    "table += \" |\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "model_type = 'GRU4Rec'\n",
    "dataset = \"mind_small\"\n",
    "name = \"Exp 3\"\n",
    "\n",
    "\n",
    "data = {name: get_best_metrics(get_last_log(model_type, dataset))}\n",
    "\n",
    "\n",
    "with open(\"README.md\", \"r\") as file:\n",
    "    markdown_content = file.read()\n",
    "\n",
    "table_regex = r\"\\| Model .*? \\|.*?\\|\\s*\\n([\\s\\S]*?)\\n\\n\"\n",
    "table_match = re.search(table_regex, markdown_content, re.MULTILINE)\n",
    "\n",
    "if table_match:\n",
    "    existing_table = table_match.group(1)\n",
    "\n",
    "    table_data = [line.split(\"|\")[1:-1] for line in existing_table.split(\"\\n\") if line.strip()]\n",
    "    new_row = [name]\n",
    "    new_row.extend([str(data[name][metric]) for metric in metrics])\n",
    "\n",
    "    table_data.append(new_row)\n",
    "    updated_table_content = \"\\n\".join(\"| \" + \" | \".join(row) + \" |\" for row in table_data)\n",
    "\n",
    "    header = \"| Model | \" + \" | \".join(metrics) + \" |\\n\"\n",
    "    updated_markdown_content = re.sub(table_regex, f\"{header}{updated_table_content}\\n\\n\", markdown_content, flags=re.MULTILINE)\n",
    "\n",
    "    with open(\"README.md\", \"w\") as file:\n",
    "        file.write(updated_markdown_content)\n",
    "else:\n",
    "    print(\"No table found in the Markdown file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(970, 1309), match='| Model | precision@1 | precision@5 | precision@1>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('data/preprocessed/mind_small/mind_small.train.inter', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
