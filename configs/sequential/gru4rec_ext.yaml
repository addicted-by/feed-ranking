train_neg_sample_args: None
additional_feat_suffix: [newsemb, absemb, clfembb, sumemb]
# additional_feat_suffix: [newsemb, absemb, clfembb]
# additional_feat_suffix: [newsemb, absemb]
# additional_feat_suffix: [newsemb]



load_col: 
    inter: [user_id, item_id, label, timestamp]
    newsemb: [nid, title_emb]
    absemb: [aid, abstract_emb]
    clfembb: [cid, clf_emb] 
    sumemb: [sid, summarization_emb]


alias_of_item_id: [nid, aid, cid, sid]
# alias_of_item_id: [nid, aid, cid]
# alias_of_item_id: [nid, aid]
# alias_of_item_id: [nid]



# score_calc: mean
# loss_type: BPR

preload_weight:
    nid: title_emb
    aid: abstract_emb
    cid: clf_emb
    sid: summarization_emb

# train_batch_size: 1024
# eval_batch_size: 1024

train_batch_size: 512
eval_batch_size: 512
hidden_size: 64
eval_step: 1
epochs: 10